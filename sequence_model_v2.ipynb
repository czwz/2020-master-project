{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "import pandas as pd\n",
    "\n",
    "# math\n",
    "import numpy as np\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Bidirectional\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# ml and data handling\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def creat_seq_map(vfile_path):\n",
    "    \"\"\"\n",
    "    (str) -> dict\n",
    "    \n",
    "    read csv file for sequence one-hot encoding and output mapping dictionary.\n",
    "    \"\"\"\n",
    "    vfile = pd.read_csv(vfile_path, index_col=None, skiprows=0)\n",
    "    return {vfile[\"One-Letter Code\"][i]:i for i in range(len(vfile[\"One-Letter Code\"]))}\n",
    "\n",
    "def seq2vec(string, outlen, vocab):\n",
    "    \"\"\"\n",
    "    (str, int, dict) -> list(list(int))\n",
    "    \n",
    "    precondition: len(string) <= outlen\n",
    "    \n",
    "    given dictionary, one-hot encode all given sequences.\n",
    "    if the length of string is smaller than outlen, it will be padded with zero to make the langth the same.\n",
    "    ---\n",
    "    string: input string (length smaller than outlen)\n",
    "    outlen: output length of vecotr.\n",
    "    vocab: the dictionary for the encoding.s\n",
    "    \"\"\"   \n",
    "    vector = [vocab[amino_acid] for amino_acid in string]\n",
    "    vector = np.pad(vector, (0,outlen-len(vector)), constant_values=20)\n",
    "    return np.array(vector)\n",
    "\n",
    "def label_data(data):\n",
    "    \"\"\"\n",
    "    (pd.DataFrame) -> pd.DataFrame\n",
    "    \n",
    "    add extra label column based on their scores (D, E).\n",
    "    1 if D+E > 0\n",
    "    0 if D+E <= 0\n",
    "    \"\"\"   \n",
    "    data.loc[(data[\"binding score\"] + data[\"digest score\"] > 0), \"label\"] = 0\n",
    "    data.loc[(data[\"binding score\"] + data[\"digest score\"] <= 0), \"label\"] = 1   \n",
    "\n",
    "    return data\n",
    "\n",
    "def screen_data(data, threshold):\n",
    "    \"\"\"\n",
    "    (pd.DataFrame, int) -> (pd.DataFrame)\n",
    "    \n",
    "    screen over a given data frame according to its two scores (D, E).\n",
    "    mask is a boolean array based on,\n",
    "    True if abs(D+E) >= threshold\n",
    "    False if abs(D+E) < threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = abs(data[\"digest score\"] + data[\"binding score\"]) >= threshold\n",
    "    return data[mask]\n",
    "\n",
    "def create_model(rnn_layers, rnn_units, fc_layers, fc_units, fc_activations, optimizer):\n",
    "    \"\"\"\n",
    "    (int, list(int), int, list(int), list(str), int, int) -> tf.keras.model\n",
    "    \n",
    "    build model for learning session.\n",
    "    \"\"\"\n",
    "    assert rnn_layers == len(rnn_units)\n",
    "    assert fc_layers == len(fc_units)\n",
    "    assert fc_layers == len(fc_activations)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # build recurent layers\n",
    "    for i in range(rnn_layers):\n",
    "        if i != rnn_layers-1:\n",
    "            model.add(Bidirectional(SimpleRNN(units=rnn_units[i], input_shape=(Tx, nx), return_sequences=True)))\n",
    "        else:\n",
    "            model.add(Bidirectional(SimpleRNN(units=rnn_units[i], input_shape=(Tx, nx))))\n",
    "        \n",
    "    # build fully connected layer\n",
    "    for i in range(fc_layers):\n",
    "        model.add(Dense(units=fc_units[i], activation=fc_activations[i]))\n",
    "        \n",
    "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load seq data\n",
    "data = pd.read_csv(\"family_101F.csv\")\n",
    "\n",
    "# exclude points according to sum of scores whithin threshold\n",
    "data = screen_data(data, 1.0)\n",
    "\n",
    "# label data according to sum of scores bigger or smaller than 0\n",
    "data = label_data(data)\n",
    "\n",
    "# shuffle the data set\n",
    "data = shuffle(data, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for seq mapping\n",
    "vocab = creat_seq_map(\"vocab.csv\")\n",
    "\n",
    "# change vector to one-hot encoding\n",
    "m = len(data)\n",
    "Tx = data[\"len\"].max()\n",
    "nx = len(vocab)\n",
    "X = np.array([to_categorical(seq2vec(data[\"seq\"][i], Tx, vocab)) for i in data.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19215, 84, 21)\n"
     ]
    }
   ],
   "source": [
    "# sanity check of output shape\n",
    "assert [m, Tx, nx] == list(X.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 split of data set\n",
    "X_train = X[:len(X)*8//10]\n",
    "Y_train = data[\"label\"].iloc[:len(X)*8//10].values\n",
    "\n",
    "X_test = X[len(X)*8//10:]\n",
    "Y_test = data[\"label\"].iloc[len(X)*8//10:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all the hyper parameters for grid search\n",
    "rnn_layers = [2]\n",
    "rnn_units = [(16, 16)]\n",
    "\n",
    "fc_layers = [2]\n",
    "fc_units = [(16, 2)]\n",
    "fc_activations = [(\"relu\", \"softmax\")]\n",
    "\n",
    "optimizer = ['SGD', 'Adam']\n",
    "\n",
    "param_grid = dict(rnn_layers = rnn_layers, \n",
    "                  rnn_units = rnn_units, \n",
    "                  fc_layers = fc_layers, \n",
    "                  fc_units = fc_units, \n",
    "                  fc_activations = fc_activations,\n",
    "                  optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rnn_layers': [2],\n",
       " 'rnn_units': [(16, 16)],\n",
       " 'fc_layers': [2],\n",
       " 'fc_units': [(16, 2)],\n",
       " 'fc_activations': [('relu', 'softmax')],\n",
       " 'optimizer': ['SGD', 'Adam']}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply grid search with 5 fold cross validation\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 1, batch_size = 320, verbose=0)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 5)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.698803 using Adam\n",
      "0.608379 (0.001171) with: 'SGD'\n",
      "0.698803 (0.007416) with: 'Adam'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_['optimizer']))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param['optimizer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
